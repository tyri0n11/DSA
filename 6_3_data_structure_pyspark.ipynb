{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/DSA/blob/main/6_3_data_structure_pyspark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ossqUjlIvaM5"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTfWU97SwbkQ"
      },
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYl-VbHmvdmW"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext()\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Y2yXzPnHtgoT",
        "outputId": "3ffa5bc0-5f33-41fc-8e00-e314b5260528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fb7282cf4c0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://aa349eb9a57d:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aT9i-sn-vkd6",
        "outputId": "5aa427c9-3580-4b77-8be2-4954d2d6ffde"
      },
      "source": [
        "# from a list\n",
        "rdd = sc.parallelize([1,2,3])\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "o0Tf5IaF0mCr",
        "outputId": "ee11e81b-236b-4b74-aff3-0dcd71d2fd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd, ctx, jrdd_deserializer=AutoBatchedSerializer(PickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 231);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mDfi99hvkgv",
        "outputId": "e98a2492-ee2b-489f-ff10-1a58c10d2770"
      },
      "source": [
        "# from a tuple\n",
        "rdd = sc.parallelize(('cat', 'dog', 'fish'))\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'dog', 'fish']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbQakoZKvklh",
        "outputId": "86661385-def6-42ab-921d-8a836615282f"
      },
      "source": [
        "# from a list of tuple\n",
        "list_t = [('cat', 'dog', 'fish'), ('orange', 'apple')]\n",
        "rdd = sc.parallelize(list_t)\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('cat', 'dog', 'fish'), ('orange', 'apple')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwHk7lOvko5",
        "outputId": "c803bcb1-e0e7-494b-9841-e95d1704bc22"
      },
      "source": [
        "# from a set\n",
        "s = {'cat', 'dog', 'fish', 'cat', 'dog', 'dog'}\n",
        "rdd = sc.parallelize(s)\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cat', 'dog', 'fish']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTp0KiO3vkwv",
        "outputId": "ff752598-b140-48c0-9f81-b95526f597b6"
      },
      "source": [
        "# from a dict\n",
        "d = {\n",
        "    'a': 100,\n",
        "    'b': 200,\n",
        "    'c': 300\n",
        "}\n",
        "rdd = sc.parallelize(d)\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYoDm1WvvlC7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c32e9dd7-c524-4870-c41c-ad3f04a73aac"
      },
      "source": [
        "# from numpy array\n",
        "import numpy as np\n",
        "arr = np.array([1,2,3,4,5,6,7,8,9])\n",
        "rdd = sc.parallelize(arr)\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "k0zcxDBkxohV",
        "outputId": "b0a04340-3c98-416c-a41f-566358f966e0"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-870385bb-a632-49e6-9cf3-67fe5f0eacfd\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-870385bb-a632-49e6-9cf3-67fe5f0eacfd\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving mtcars.csv to mtcars.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mtcars.csv': b',mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb\\r\\nMazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4\\r\\nMazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4\\r\\nDatsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1\\r\\nHornet 4 Drive,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1\\r\\nHornet Sportabout,18.7,8,360,175,3.15,3.44,17.02,0,0,3,2\\r\\nValiant,18.1,6,225,105,2.76,3.46,20.22,1,0,3,1\\r\\nDuster 360,14.3,8,360,245,3.21,3.57,15.84,0,0,3,4\\r\\nMerc 240D,24.4,4,146.7,62,3.69,3.19,20,1,0,4,2\\r\\nMerc 230,22.8,4,140.8,95,3.92,3.15,22.9,1,0,4,2\\r\\nMerc 280,19.2,6,167.6,123,3.92,3.44,18.3,1,0,4,4\\r\\nMerc 280C,17.8,6,167.6,123,3.92,3.44,18.9,1,0,4,4\\r\\nMerc 450SE,16.4,8,275.8,180,3.07,4.07,17.4,0,0,3,3\\r\\nMerc 450SL,17.3,8,275.8,180,3.07,3.73,17.6,0,0,3,3\\r\\nMerc 450SLC,15.2,8,275.8,180,3.07,3.78,18,0,0,3,3\\r\\nCadillac Fleetwood,10.4,8,472,205,2.93,5.25,17.98,0,0,3,4\\r\\nLincoln Continental,10.4,8,460,215,3,5.424,17.82,0,0,3,4\\r\\nChrysler Imperial,14.7,8,440,230,3.23,5.345,17.42,0,0,3,4\\r\\nFiat 128,32.4,4,78.7,66,4.08,2.2,19.47,1,1,4,1\\r\\nHonda Civic,30.4,4,75.7,52,4.93,1.615,18.52,1,1,4,2\\r\\nToyota Corolla,33.9,4,71.1,65,4.22,1.835,19.9,1,1,4,1\\r\\nToyota Corona,21.5,4,120.1,97,3.7,2.465,20.01,1,0,3,1\\r\\nDodge Challenger,15.5,8,318,150,2.76,3.52,16.87,0,0,3,2\\r\\nAMC Javelin,15.2,8,304,150,3.15,3.435,17.3,0,0,3,2\\r\\nCamaro Z28,13.3,8,350,245,3.73,3.84,15.41,0,0,3,4\\r\\nPontiac Firebird,19.2,8,400,175,3.08,3.845,17.05,0,0,3,2\\r\\nFiat X1-9,27.3,4,79,66,4.08,1.935,18.9,1,1,4,1\\r\\nPorsche 914-2,26,4,120.3,91,4.43,2.14,16.7,0,1,5,2\\r\\nLotus Europa,30.4,4,95.1,113,3.77,1.513,16.9,1,1,5,2\\r\\nFord Pantera L,15.8,8,351,264,4.22,3.17,14.5,0,1,5,4\\r\\nFerrari Dino,19.7,6,145,175,3.62,2.77,15.5,0,1,5,6\\r\\nMaserati Bora,15,8,301,335,3.54,3.57,14.6,0,1,5,8\\r\\nVolvo 142E,21.4,4,121,109,4.11,2.78,18.6,1,1,4,2'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG7gZilMxozq",
        "outputId": "f0159167-d5e0-4979-d359-1a7258f7171b"
      },
      "source": [
        "mtcars = spark.read.csv(path='./mtcars.csv',\n",
        "                        sep=',',\n",
        "                        encoding='UTF-8',\n",
        "                        comment=None,\n",
        "                        header=True,\n",
        "                        inferSchema=True)\n",
        "mtcars.show(n=5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|_c0              |mpg |cyl|disp |hp |drat|wt   |qsec |vs |am |gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|Mazda RX4        |21.0|6  |160.0|110|3.9 |2.62 |16.46|0  |1  |4   |4   |\n",
            "|Mazda RX4 Wag    |21.0|6  |160.0|110|3.9 |2.875|17.02|0  |1  |4   |4   |\n",
            "|Datsun 710       |22.8|4  |108.0|93 |3.85|2.32 |18.61|1  |1  |4   |1   |\n",
            "|Hornet 4 Drive   |21.4|6  |258.0|110|3.08|3.215|19.44|1  |0  |3   |1   |\n",
            "|Hornet Sportabout|18.7|8  |360.0|175|3.15|3.44 |17.02|0  |0  |3   |2   |\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(mtcars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "Un3GjpEEvGug",
        "outputId": "060c2030-610f-4bef-a1cf-54e4e196f969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf, sql_ctx)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`::\n",
              "\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method::\n",
              "\n",
              "    ageCol = people.age\n",
              "\n",
              "A more concrete example::\n",
              "\n",
              "    # To create DataFrame using SparkSession\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "    department = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "    people.filter(people.age &gt; 30).join(department, people.deptId == department.id) \\\n",
              "      .groupBy(department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;})\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 41);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CA70ZGzixpAs",
        "outputId": "903b38bd-79a9-4b24-d46b-b8187fdcb922"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "rdd = sc.parallelize([\n",
        "    Row(x=[1,2,3], y=['a','b','c']),\n",
        "    Row(x=[4,5,6], y=['e','f','g'])\n",
        "])\n",
        "rdd.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(x=[1, 2, 3], y=['a', 'b', 'c']), Row(x=[4, 5, 6], y=['e', 'f', 'g'])]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddoz16HdxpUO",
        "outputId": "20773fc3-bd93-41d3-c4d0-4f5d26e1dc5e"
      },
      "source": [
        "spark_df = spark.createDataFrame(rdd)\n",
        "spark_df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|        x|        y|\n",
            "+---------+---------+\n",
            "|[1, 2, 3]|[a, b, c]|\n",
            "|[4, 5, 6]|[e, f, g]|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(spark_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "5dxkwgqH1EKh",
        "outputId": "88e18961-d596-415c-b307-6a93936214b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf, sql_ctx)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`::\n",
              "\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method::\n",
              "\n",
              "    ageCol = people.age\n",
              "\n",
              "A more concrete example::\n",
              "\n",
              "    # To create DataFrame using SparkSession\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "    department = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "    people.filter(people.age &gt; 30).join(department, people.deptId == department.id) \\\n",
              "      .groupBy(department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;})\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 41);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "g1BhbbZjxplM",
        "outputId": "9d06b605-1717-4f58-b3c3-506b34f16d58"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "    'x': [[1,2,3], [4,5,6]],\n",
        "    'y': [['a','b','c'], ['e','f','g']]\n",
        "})\n",
        "pdf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           x          y\n",
              "0  [1, 2, 3]  [a, b, c]\n",
              "1  [4, 5, 6]  [e, f, g]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93554905-fecd-44de-989e-de3ff948cefa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[1, 2, 3]</td>\n",
              "      <td>[a, b, c]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[4, 5, 6]</td>\n",
              "      <td>[e, f, g]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93554905-fecd-44de-989e-de3ff948cefa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-93554905-fecd-44de-989e-de3ff948cefa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-93554905-fecd-44de-989e-de3ff948cefa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-44b5bb9c-5e92-4752-85c9-569c3ca8c0ba\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-44b5bb9c-5e92-4752-85c9-569c3ca8c0ba')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-44b5bb9c-5e92-4752-85c9-569c3ca8c0ba button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "pdf",
              "summary": "{\n  \"name\": \"pdf\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"x\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(pdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "XE4Lg2SZ1Lk9",
        "outputId": "7f819d2d-a8f8-4ca6-86ad-383eab94f06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index.\n",
              "\n",
              "    .. versionchanged:: 0.25.0\n",
              "       If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 475);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwPa5ZzYyJwk",
        "outputId": "d3e9fcb7-264d-4668-e1c2-334b859690a2"
      },
      "source": [
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/pandas/conversion.py:331: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for column, series in pdf.iteritems():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+\n",
            "|        x|        y|\n",
            "+---------+---------+\n",
            "|[1, 2, 3]|[a, b, c]|\n",
            "|[4, 5, 6]|[e, f, g]|\n",
            "+---------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGsgZi1K1Pw7",
        "outputId": "ccef1ff2-ca8c-4edd-99b7-9aae6ba84c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88PgvJhqyJ2f",
        "outputId": "04e1c1af-9641-4d89-85e4-e937f3245a26"
      },
      "source": [
        "my_list = [['a', 1], ['b', 2]]\n",
        "df = spark.createDataFrame(my_list, ['letter', 'number'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|letter|number|\n",
            "+------+------+\n",
            "|     a|     1|\n",
            "|     b|     2|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OugrQxJmyJ7N",
        "outputId": "682f9958-f18b-4151-91c6-888c9206c084"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('letter', 'string'), ('number', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-E8SbalyJ-V",
        "outputId": "a59309af-5754-42de-9aa4-d4904e6cd7bc"
      },
      "source": [
        "my_list = [['a', 1], ['b', 2]]\n",
        "df = spark.createDataFrame(my_list, ['my_column'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+\n",
            "|my_column| _2|\n",
            "+---------+---+\n",
            "|        a|  1|\n",
            "|        b|  2|\n",
            "+---------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbEuApeQyKEw",
        "outputId": "21501a71-bda0-4a27-cdda-0c82be85c15b"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('my_column', 'string'), ('_2', 'bigint')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "649JhDGGyh5E",
        "outputId": "cdc05bef-fd4d-4cc5-987a-6467fedb1692"
      },
      "source": [
        "my_list = [(['a', 1], ['b', 2])]\n",
        "df = spark.createDataFrame(my_list, ['x', 'y'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|     x|     y|\n",
            "+------+------+\n",
            "|[a, 1]|[b, 2]|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9GOI987Hc6br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qp89ZCO4yrZ_"
      },
      "source": [
        "\n",
        "\n",
        "## Column instance\n",
        "\n",
        "Column instances can be created in two ways:\n",
        "\n",
        "1. directly select a column out of a *DataFrame*: `df.colName`\n",
        "2. create from a column expression: `df.colName + 1`\n",
        "\n",
        "Technically, there is only one way to create a column instance. Column expressions start from a column instance.\n",
        "\n",
        "**Remember how to create column instances, because this is usually the starting point if we want to operate DataFrame columns.**\n",
        "\n",
        "The column classes come with some methods that can operate on a column instance. ***However, almost all functions from the `pyspark.sql.functions` module take one or more column instances as argument(s)***. These functions are important for data manipulation tools.\n",
        "\n",
        "## DataFrame column methods\n",
        "\n",
        "### Methods that take column names as arguments:\n",
        "\n",
        "* `corr(col1, col2)`: two column names.\n",
        "* `cov(col1, col2)`: two column names.\n",
        "* `crosstab(col1, col2)`: two column names.\n",
        "* `describe(*cols)`: ***`*cols` refers to only column names (strings).***\n",
        "\n",
        "### Methods that take column names or column expressions or **both** as arguments:\n",
        "\n",
        "* `cube(*cols)`: column names (string) or column expressions or **both**.\n",
        "* `drop(*cols)`: ***a list of column names OR a single column expression.***\n",
        "* `groupBy(*cols)`: column name (string) or column expression or **both**.\n",
        "* `rollup(*cols)`: column name (string) or column expression or **both**.\n",
        "* `select(*cols)`: column name (string) or column expression or **both**.\n",
        "* `sort(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
        "* `sortWithinPartitions(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
        "* `orderBy(*cols, **kwargs)`: column name (string) or column expression or **both**.\n",
        "* `sampleBy(col, fractions, sed=None)`: a column name.\n",
        "* `toDF(*cols)`: **a list of column names (string).**\n",
        "* `withColumn(colName, col)`: `colName` refers to column name; `col` refers to a column expression.\n",
        "* `withColumnRenamed(existing, new)`: takes column names as arguments.\n",
        "* `filter(condition)`: ***condition** refers to a column expression that returns `types.BooleanType` of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNlxBBvoyivZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxCqRTnfzG-o"
      },
      "source": [
        "## DataFrame to RDD\n",
        "A **DataFrame** can be easily converted to an **RDD** by calling the `pyspark.sql.DataFrame.rdd()` function. Each element in the returned RDD is an **pyspark.sql.Row** object. An Row is a list of key-value pairs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aReMmbzXyjQP",
        "outputId": "8df93707-2d14-41b4-80c9-9e328061dd66"
      },
      "source": [
        "mtcars.rdd.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(_c0='Mazda RX4', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.62, qsec=16.46, vs=0, am=1, gear=4, carb=4),\n",
              " Row(_c0='Mazda RX4 Wag', mpg=21.0, cyl=6, disp=160.0, hp=110, drat=3.9, wt=2.875, qsec=17.02, vs=0, am=1, gear=4, carb=4)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkwBaHA8zLou"
      },
      "source": [
        "With an RDD object, we can apply a set of mapping functions, such as **map**, **mapValues**, **flatMap**, **flatMapValues** and a lot of other methods that come from RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ald1iZXXyjbj",
        "outputId": "01408e9b-6cb0-4b2c-b00a-8d8b10a08bc3"
      },
      "source": [
        "mtcars_map = mtcars.rdd.map(lambda x: (x['_c0'], x['mpg']))\n",
        "mtcars_map.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', 21.0),\n",
              " ('Mazda RX4 Wag', 21.0),\n",
              " ('Datsun 710', 22.8),\n",
              " ('Hornet 4 Drive', 21.4),\n",
              " ('Hornet Sportabout', 18.7)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8rhhDHcyjkI",
        "outputId": "14de7213-6bfd-482d-ef85-91ab8f290f24"
      },
      "source": [
        "mtcars_mapvalues = mtcars_map.mapValues(lambda x: [x, x * 10])\n",
        "mtcars_mapvalues.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', [21.0, 210.0]),\n",
              " ('Mazda RX4 Wag', [21.0, 210.0]),\n",
              " ('Datsun 710', [22.8, 228.0]),\n",
              " ('Hornet 4 Drive', [21.4, 214.0]),\n",
              " ('Hornet Sportabout', [18.7, 187.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oa4HsUBXzZBM"
      },
      "source": [
        "## RDD to DataFrame\n",
        "\n",
        "To convert an RDD to a DataFrame, we can use the `SparkSession.createDataFrame()` function. Every element in the RDD **has be to an Row object**.\n",
        "\n",
        "Create an RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcfUFmr2yjqY",
        "outputId": "5fadb44f-b6c2-4ac1-f0b9-73c9f790f8ce"
      },
      "source": [
        "rdd_raw = sc.textFile('./mtcars.csv')\n",
        "rdd_raw.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb',\n",
              " 'Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4',\n",
              " 'Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4',\n",
              " 'Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1',\n",
              " 'Hornet 4 Drive,21.4,6,258,110,3.08,3.215,19.44,1,0,3,1']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msA2CU7Pyjtk",
        "outputId": "6e970f7c-3114-4109-d6e7-56f4d5f48a96"
      },
      "source": [
        "header = rdd_raw.map(lambda x: x.split(',')).filter(lambda x: x[1] == 'mpg').collect()[0]\n",
        "header[0] = 'model'\n",
        "header"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['model',\n",
              " 'mpg',\n",
              " 'cyl',\n",
              " 'disp',\n",
              " 'hp',\n",
              " 'drat',\n",
              " 'wt',\n",
              " 'qsec',\n",
              " 'vs',\n",
              " 'am',\n",
              " 'gear',\n",
              " 'carb']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6DAQQQszlAW"
      },
      "source": [
        "#### Save the rest to a new RDD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT_7Fki8yjw1",
        "outputId": "7760ab0a-ff1c-43be-886d-2da5f81aa500"
      },
      "source": [
        "rdd = rdd_raw.map(lambda x: x.split(',')).filter(lambda x: x[1] != 'mpg')\n",
        "rdd.take(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Mazda RX4',\n",
              "  '21',\n",
              "  '6',\n",
              "  '160',\n",
              "  '110',\n",
              "  '3.9',\n",
              "  '2.62',\n",
              "  '16.46',\n",
              "  '0',\n",
              "  '1',\n",
              "  '4',\n",
              "  '4'],\n",
              " ['Mazda RX4 Wag',\n",
              "  '21',\n",
              "  '6',\n",
              "  '160',\n",
              "  '110',\n",
              "  '3.9',\n",
              "  '2.875',\n",
              "  '17.02',\n",
              "  '0',\n",
              "  '1',\n",
              "  '4',\n",
              "  '4']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlGU914Uzsct"
      },
      "source": [
        "First we define a function which takes a list of column names and a list of values and create a Row of key-value pairs. **Since keys in an Row object are variable names, we cant simply pass a dictionary to the Row() function**. We can think of a dictionary as an argument list and use the `**` to unpack the argument list.\n",
        "\n",
        "See an example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_GuQ5lvzo6B",
        "outputId": "eacdd52b-8c0c-4847-8f4e-e7ca1401104c"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "my_dict = dict(zip(['a', 'b', 'c'], range(1, 4)))\n",
        "Row(**my_dict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(a=1, b=2, c=3)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itjf_nhQz1ze"
      },
      "source": [
        "#### Lets define the function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmQpFkdX06Cw"
      },
      "source": [
        "def dict_to_row(keys, values):\n",
        "    row_dict = dict(zip(keys, values))\n",
        "    return Row(**row_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7Hju02Ezo9A",
        "outputId": "046e22d1-d202-44e3-c474-367e67767b02"
      },
      "source": [
        "rdd_rows = rdd.map(lambda x: dict_to_row(header, x))\n",
        "rdd_rows.take(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(model='Mazda RX4', mpg='21', cyl='6', disp='160', hp='110', drat='3.9', wt='2.62', qsec='16.46', vs='0', am='1', gear='4', carb='4'),\n",
              " Row(model='Mazda RX4 Wag', mpg='21', cyl='6', disp='160', hp='110', drat='3.9', wt='2.875', qsec='17.02', vs='0', am='1', gear='4', carb='4'),\n",
              " Row(model='Datsun 710', mpg='22.8', cyl='4', disp='108', hp='93', drat='3.85', wt='2.32', qsec='18.61', vs='1', am='1', gear='4', carb='1')]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check\n",
        "type(rdd_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJuMmga3zOGg",
        "outputId": "ec4f2130-c50a-440b-ca96-217b59b3977d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGD65FaYzpAW",
        "outputId": "3511a865-b761-4113-9a80-7fb3887178f0"
      },
      "source": [
        "df = spark.createDataFrame(rdd_rows)\n",
        "df.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+----+---+----+-----+-----+---+---+----+----+\n",
            "|            model| mpg|cyl|disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------------+----+---+----+---+----+-----+-----+---+---+----+----+\n",
            "|        Mazda RX4|  21|  6| 160|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|  21|  6| 160|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4| 108| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6| 258|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8| 360|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "+-----------------+----+---+----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37LEBG83zpDT"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlX1Uv9P4vbQ"
      },
      "source": [
        "## Merge and split columns\n",
        "\n",
        "Sometimes we need to merge multiple columns in a Dataframe into one column, or split a column into multiple columns. We can easily achieve this by converting a DataFrame to RDD, applying map functions to manipulate elements, and then converting the RDD back to a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDEYdOBWzpF-",
        "outputId": "4667e580-9f5f-4dd1-a044-19ad81f37e0a"
      },
      "source": [
        "# adjust first column name\n",
        "colnames = mtcars.columns\n",
        "colnames[0] = 'model'\n",
        "mtcars = mtcars.rdd.toDF(colnames)\n",
        "mtcars.show(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|            model| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc_MbWmI4-dH"
      },
      "source": [
        "### Merge multiple columns\n",
        "\n",
        "We convert DataFrame to RDD and then apply the **map** function to merge values and convert\n",
        "elements to **Row** objects."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(mtcars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "3WUbwxJu0HU_",
        "outputId": "b0bfb9fe-5933-402e-bc92-de309fa73529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.dataframe.DataFrame</b><br/>def __init__(jdf, sql_ctx)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/spark-3.1.1-bin-hadoop3.2/python/pyspark/sql/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`::\n",
              "\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method::\n",
              "\n",
              "    ageCol = people.age\n",
              "\n",
              "A more concrete example::\n",
              "\n",
              "    # To create DataFrame using SparkSession\n",
              "    people = spark.read.parquet(&quot;...&quot;)\n",
              "    department = spark.read.parquet(&quot;...&quot;)\n",
              "\n",
              "    people.filter(people.age &gt; 30).join(department, people.deptId == department.id) \\\n",
              "      .groupBy(department.name, &quot;gender&quot;).agg({&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;})\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 41);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnN60y2Wyj10",
        "outputId": "ec86633d-b314-41fb-e087-f1a1b37fdf40"
      },
      "source": [
        "from pyspark.sql import Row\n",
        "mtcars_rdd = mtcars.rdd.map(lambda x: Row(model=x[0], values=x[1:]))\n",
        "mtcars_rdd.take(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(model='Mazda RX4', values=(21.0, 6, 160.0, 110, 3.9, 2.62, 16.46, 0, 1, 4, 4)),\n",
              " Row(model='Mazda RX4 Wag', values=(21.0, 6, 160.0, 110, 3.9, 2.875, 17.02, 0, 1, 4, 4)),\n",
              " Row(model='Datsun 710', values=(22.8, 4, 108.0, 93, 3.85, 2.32, 18.61, 1, 1, 4, 1)),\n",
              " Row(model='Hornet 4 Drive', values=(21.4, 6, 258.0, 110, 3.08, 3.215, 19.44, 1, 0, 3, 1)),\n",
              " Row(model='Hornet Sportabout', values=(18.7, 8, 360.0, 175, 3.15, 3.44, 17.02, 0, 0, 3, 2))]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(mtcars_rdd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_AQhArJ0NqM",
        "outputId": "6ae92244-b589-4a1a-fa61-ec52e2ed6894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvauw7WR5D_I"
      },
      "source": [
        "Then we create a new DataFrame from the obtained RDD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpbQS_Gk5Cdu",
        "outputId": "74e77b95-e9bb-426e-8695-6cfd87e8cd43"
      },
      "source": [
        "mtcars_df = spark.createDataFrame(mtcars_rdd)\n",
        "mtcars_df.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------------------------------------------+\n",
            "|model            |values                                               |\n",
            "+-----------------+-----------------------------------------------------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9, 2.62, 16.46, 0, 1, 4, 4}  |\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9, 2.875, 17.02, 0, 1, 4, 4} |\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85, 2.32, 18.61, 1, 1, 4, 1}  |\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08, 3.215, 19.44, 1, 0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15, 3.44, 17.02, 0, 0, 3, 2} |\n",
            "+-----------------+-----------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rtFJ4ro5OWV"
      },
      "source": [
        "## Split one column\n",
        "\n",
        "We use the above DataFrame as our example data. Again, we need to convert the DataFrame to an RDD to achieve our goal.\n",
        "\n",
        "Let's split the **values** column into two columns: x1 and x2. The first 4 values will be in column **x1** and the remaining values will be in column **x2**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogaLQgXZ5CgB",
        "outputId": "ce5ffb12-be67-4116-d98a-c5843eec8e59"
      },
      "source": [
        "mtcars_rdd_2 = mtcars_df.rdd.map(lambda x: Row(model=x[0], x1=x[1][:5], x2=x[1][5:]))\n",
        "# convert RDD back to DataFrame\n",
        "mtcars_df_2 = spark.createDataFrame(mtcars_rdd_2)\n",
        "mtcars_df_2.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------------------------+--------------------------+\n",
            "|model            |x1                         |x2                        |\n",
            "+-----------------+---------------------------+--------------------------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9} |{2.62, 16.46, 0, 1, 4, 4} |\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9} |{2.875, 17.02, 0, 1, 4, 4}|\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85} |{2.32, 18.61, 1, 1, 4, 1} |\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08}|{3.215, 19.44, 1, 0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15}|{3.44, 17.02, 0, 0, 3, 2} |\n",
            "+-----------------+---------------------------+--------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gfk7dlci5CjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f541842d-508f-4884-dd64-988aced697ff"
      },
      "source": [
        "mtcars_rdd_3 = mtcars_df.rdd.map(lambda x: Row(model=x[0], x1=x[1][:7], x2=x[1][7:]))\n",
        "# convert RDD back to DataFrame\n",
        "mtcars_df_3 = spark.createDataFrame(mtcars_rdd_3)\n",
        "mtcars_df_3.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----------------------------------------+------------+\n",
            "|model            |x1                                       |x2          |\n",
            "+-----------------+-----------------------------------------+------------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9, 2.62, 16.46}  |{0, 1, 4, 4}|\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9, 2.875, 17.02} |{0, 1, 4, 4}|\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85, 2.32, 18.61}  |{1, 1, 4, 1}|\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08, 3.215, 19.44}|{1, 0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15, 3.44, 17.02} |{0, 0, 3, 2}|\n",
            "+-----------------+-----------------------------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6FK1qVA5Cme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5448f9-14d5-4451-b80a-4e24c522ff1a"
      },
      "source": [
        "mtcars_rdd_4 = mtcars_df.rdd.map(lambda x: Row(model=x[0], x1=x[1][:5], x2=x[1][5:8], x3=x[1][8:]))\n",
        "# convert RDD back to DataFrame\n",
        "mtcars_df_4 = spark.createDataFrame(mtcars_rdd_4)\n",
        "mtcars_df_4.show(5, truncate=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+---------------------------+-----------------+---------+\n",
            "|model            |x1                         |x2               |x3       |\n",
            "+-----------------+---------------------------+-----------------+---------+\n",
            "|Mazda RX4        |{21.0, 6, 160.0, 110, 3.9} |{2.62, 16.46, 0} |{1, 4, 4}|\n",
            "|Mazda RX4 Wag    |{21.0, 6, 160.0, 110, 3.9} |{2.875, 17.02, 0}|{1, 4, 4}|\n",
            "|Datsun 710       |{22.8, 4, 108.0, 93, 3.85} |{2.32, 18.61, 1} |{1, 4, 1}|\n",
            "|Hornet 4 Drive   |{21.4, 6, 258.0, 110, 3.08}|{3.215, 19.44, 1}|{0, 3, 1}|\n",
            "|Hornet Sportabout|{18.7, 8, 360.0, 175, 3.15}|{3.44, 17.02, 0} |{0, 3, 2}|\n",
            "+-----------------+---------------------------+-----------------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "1. Split `mtcars_df` into 5 columns given that the first column is `model`, call the new dataframe as `mtcars_df_5`.\n",
        "2. Merge all columns (except the first colums `model`) of `mtcars_df_5` to one column `X`. Call this new dataframe as `mtcars_df_6`\n",
        "3. Split `mtcars_df` into some columns given that the first column is `model`. From the second column and more, each column has three values, while the last column contains the remining values. Then we call the new dataframe as `mtcars_df_7`.\n"
      ],
      "metadata": {
        "id": "npaTE-N806u2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Do the same thing for titanic dataset."
      ],
      "metadata": {
        "id": "xl67_RhkvPG_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FAAHcsL47JJ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}